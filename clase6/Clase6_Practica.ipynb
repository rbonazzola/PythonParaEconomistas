{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [¿Cómo les resultó la última tarea?](https://forms.gle/fNxjn8A8TWVxK1Xj7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Preguntas de la clase asincrónica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuestionario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) ¿Cómo escribir la matriz `((2,2),(2,2))` usando `np.ones` y producto de un escalar por un `nparray`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "2 * np.ones((2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) ¿Qué error nos da `numpy` cuando queremos calcular la inversa de una matriz cuadrada no invertible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "inv(np.ones((3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte vamos a ver los fundamentos del aprendizaje profundo. Vamos a ver cómo funcionan las redes neuronales convolucionales (CNNs), que es el tipo de red neuronal que se usa para procesamiento de imágenes.\n",
    "Luego vamos a implementar una red neuronal convolucional que aprende a reconocer dígitos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teoría\n",
    "#### ¿Qué es una red neuronal artificial (ANN)?\n",
    "Una red neuronal artificial es un modelo matemático que se puede representar como una sucesión de _capas_ que van desde los datos de entrada ($X$) a los datos de salida ($y$, o etiquetas). Cada capa se \"comunica\" sólo con la inmediata anterior y posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](figuras/NN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las capas intermedias se llaman _capas ocultas_ o _latentes_. Cada neurona de una capa recibe como entrada una combinación lineal de las salidas de las neuronas de la capa anterior. \n",
    "\n",
    "Cada flecha en la figura de arriba representa el _peso_ que le damos a la neurona de la izquierda en la entrada de la neurona de la derecha.\n",
    "\n",
    "Estos pesos son los parámetros que la red \"aprende\", de la misma manera que en una regresión lineal sencilla ajustábamos pendiente y ordenada al origen de la recta.\n",
    "\n",
    "**Pregunta**: *¿Cuántos parámetros \"ajustables\" tiene la red de arriba?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones de activación\n",
    "Como sabemos de álgebra lineal, el proceso que describimos hasta ahora equivale a multiplicar vectores por matrices sucesivas veces, es decir hacer $y = B(Ax)$.\n",
    "\n",
    "Pero esto es equivalente a multiplicar por una sola matriz $C=BA$, es decir, a no tener ninguna capa oculta!\n",
    "\n",
    "En lugar de hacer esto, para tener más flexibilidad en el tipo de comportamiento que la red captura, en cada capa utilizamos una **función de activación no lineal**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cómo entrenamos una red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general usamos una técnica **iterativa** que se llama *descenso por gradiente*, donde la \"x\" es el vector de todos los parámetros de la red (la derivada se convierte en un gradiente) y la función que queremos optimizar es una medida del error que la red está cometiendo en la iteración presente. \n",
    "\n",
    "Esta función a optimizar se llama **función de pérdida** (*loss function*) o **función de costo**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](figuras/gradient_descent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular el gradiente respecto de cada uno de los parámetros, se debe aplicar la **regla de la cadena** debido a las interdependencias que hay entre las distintas neuronas de la red. La aplicación de la regla en la cadena para redes neuronales se llama **retropropagación**.\n",
    "\n",
    "En cada iteración, el valor de los pesos de la red se corrige en una cantidad dada por el gradiente de la función de pérdida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ver también\n",
    "- [Este](https://www.youtube.com/watch?v=aircAruvnKk) es un video **muy bueno** para ganar una mejor intuición de lo que ocurre en una red neuronal.\n",
    "- Estos videos del mismo canal explican la matemática detrás de cómo se entrena una red:\n",
    "  - [Descenso por gradiente](https://www.youtube.com/watch?v=IHZwWFHWa-w)\n",
    "  - [Retropropagación](https://www.youtube.com/watch?v=Ilg3gGewQ5U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así luce una función de pérdida real (respecto a sólo dos parámetros!):\n",
    "![caption](figuras/loss_function_nn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver cómo usar PyTorch para implementar redes neuronales.\n",
    "Para importar la librería, ejecutamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La versión de PyTorch que tengo instalada es la %s.\" % (torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo hacemos para generar la red neuronal de más arriba?\n",
    "\n",
    "Primero, definamos la **arquitectura** de la red neuronal: 2 neuronas de entrada, 1 capa oculta con 3 neuronas y 2 neuronas de salida.\n",
    "\n",
    "Para ello tenemos que construir una clase que _herede_ de `nn.Module` (¿recuerdan herencia de clases [semana 3]?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NuestraPrimeraRed(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NuestraPrimeraRed, self).__init__()\n",
    "        self.capa12 = nn.Linear(2, 3)\n",
    "        self.capa23 = nn.Linear(3, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.capa12(x)\n",
    "        x = F.sigmoid(x)\n",
    "        y = self.capa23(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos inicializar el modelo, llamando al constructor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = NuestraPrimeraRed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo vamos a ver cómo entrenaríamos una red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redes neuronales convolucionales (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las CNNs se basan en el uso de **filtros convolucionales**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, este filtro produce una nueva imagen que resalta los bordes horizontales:\n",
    "<img src=\"figuras/filtro_convolucional.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![caption](figuras/cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a trabajar con un dataset llamado **MNIST**, el cual contiene imágenes de dígitos de 28x28 píxeles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para bajarlo, podemos usar PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(En [este link](https://pytorch.org/docs/stable/torchvision/datasets.html) van a poder encontrar otros datasets.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinemos un poco los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnist_trainset.classes)\n",
    "print(mnist_trainset.train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualicemos las imágenes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig=plt.figure(figsize=(20, 10))\n",
    "for i in range(1, 16):\n",
    "    img = transforms.ToPILImage(mode='L')(mnist_trainset[i][0])\n",
    "    fig.add_subplot(1, 16, i)\n",
    "    plt.title(mnist_trainset[i][1])\n",
    "    plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mnist_trainset.data.shape)\n",
    "print(mnist_trainset.data[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "mnist_valset, mnist_testset = torch.utils.data.random_split(mnist_testset, [int(0.9 * len(mnist_testset)), int(0.1 * len(mnist_testset))])\n",
    "\n",
    "# para traernos un subconjuntos de los datos\n",
    "# train_dataloader = torch.utils.data.DataLoader(Subset(mnist_trainset, range(5000)), batch_size=64, shuffle=True,)\n",
    "# val_dataloader = torch.utils.data.DataLoader(Subset(mnist_valset, range(1000)), batch_size=32, shuffle=False)\n",
    "# test_dataloader = torch.utils.data.DataLoader(Subset(mnist_testset, range(500)), batch_size=32, shuffle=False)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(mnist_valset, batch_size=32, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(mnist_testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0) Definamos la arquitectura de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NuestraSegundaRed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NuestraSegundaRed, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Inicializamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = NuestraSegundaRed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Definimos la **función de pérdida**. En este caso usamos la *entropía cruzada* (`CrossEntropyLoss`), que es la forma estándar de medir el error cuando la salida es una variable categórica (en lugar de una continua):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterio = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Definimos el algoritmo que vamos a usar para entrenar la red (el **optimizador**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizador = torch.optim.Adam(modelo.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_epochs = 5\n",
    "train_loss = list()\n",
    "val_loss = list()\n",
    "best_val_loss = 1\n",
    "\n",
    "for epoch in range(no_epochs):\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    modelo.train()\n",
    "\n",
    "    # training\n",
    "    for itr, (image, label) in enumerate(train_dataloader):\n",
    "        optimizador.zero_grad()\n",
    "\n",
    "        pred = modelo(image)\n",
    "\n",
    "        loss = criterio(pred, label)\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizador.step()\n",
    "\n",
    "    total_train_loss = total_train_loss / (itr + 1)\n",
    "    train_loss.append(total_train_loss)\n",
    "    \n",
    "    # validation\n",
    "    modelo.eval()\n",
    "    total = 0\n",
    "    for itr, (image, label) in enumerate(val_dataloader):\n",
    "        pred = modelo(image)\n",
    "\n",
    "        loss = criterio(pred, label)\n",
    "        total_val_loss += loss.item()\n",
    "\n",
    "        pred = torch.nn.functional.softmax(pred, dim=1)\n",
    "        for i, p in enumerate(pred):\n",
    "            if label[i] == torch.max(p.data, 0)[1]:\n",
    "                total = total + 1\n",
    "\n",
    "    accuracy = total / len(mnist_valset)\n",
    "\n",
    "    total_val_loss = total_val_loss / (itr + 1)\n",
    "    val_loss.append(total_val_loss)\n",
    "\n",
    "    hora = time.strftime(\"%H:%M:%S\") \n",
    "    print('\\n{} - Epoch: {}/{}, Train Loss: {:.8f}, Val Loss: {:.8f}, Val Accuracy: {:.8f}'.format(hora, epoch + 1, no_epochs, total_train_loss, total_val_loss, accuracy))\n",
    "\n",
    "    if total_val_loss < best_val_loss:\n",
    "        best_val_loss = total_val_loss\n",
    "        print(\"Saving the model state dictionary for Epoch: {} with Validation loss: {:.8f}\".format(epoch + 1, total_val_loss))\n",
    "        torch.save(modelo.state_dict(), \"checkpoints/model.dth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos cargar los parámetros del modelo ya entrenado desde el archivo que guardamos en la celda de arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.load_state_dict(torch.load(\"checkpoints/model.dth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig=plt.figure(figsize=(20, 10))\n",
    "plt.plot(np.arange(1, no_epochs+1), train_loss, label=\"Train loss\")\n",
    "plt.plot(np.arange(1, no_epochs+1), val_loss, label=\"Validation loss\")\n",
    "plt.xlabel('Loss')\n",
    "plt.ylabel('Epochs')\n",
    "plt.title(\"Loss Plots\")\n",
    "plt.legend(loc='upper right')\n",
    "# plt.show()\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar modelo en datos reales (tarea?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el modelo con datos reales, pueden dibujar un dígito usando un software como Paint o GIMP, guardarlo en la resolución correcta (28x28px) y leerlo con PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se lo dejamos como tarea (opcional). Para ver los detalles de cómo hacerlo pueden googlear y/o consultarme por Slack."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
