{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller Introducción a la Programación en Python\n",
    "## Bienvenidos a la clase 5\n",
    "\n",
    "### Anuncios y temario para hoy\n",
    "\n",
    "- Pull de GitHub\n",
    "- Cuestionario dificultad tarea\n",
    "- Respuestas del cuestionario de los videos\n",
    "- Dudas de la teoría\n",
    "- Ejercicio práctico: Analisis de sentimiento de tweets de Joe Biden pre y post elecciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuestionario dificultad Tarea\n",
    "https://forms.gle/pnMdLxTdYsWhRGyS9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuestas a las preguntas de los videos:\n",
    "https://docs.google.com/forms/d/e/1FAIpQLSfb7zlEHh3gllD3iUUWwPCMwyQPd0Z04F3XpArSKQzPkYvGHA/viewform?usp=pp_url&entry.1318485631=Respuesta+Satisfactoria+(Successful+responses)&entry.330305262=Una+celda+de+una+tabla&entry.871102831=Tabula&entry.871102831=PyPDF2&entry.871102831=Minecart&entry.2076477619=La+puedo+trabajar+desde+python+con+el+paquete+psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de sentimiento de tweets de Joe Biden pre y post elecciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos los paquetes a utilizar\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "from datetime import datetime\n",
    "\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear con Sublime (u otro editor de texto) un archivo llamado `twitter_keys.txt` dentro de la carpeta `clase5` y guardar las 4 claves, una por línea, en el siguiente orden:\n",
    "- API key\n",
    "- API key secret\n",
    "- Access token\n",
    "- Access token secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos variables que contienen nuestas claves de autenticación con la API\n",
    "with open(\"twitter_keys.txt\") as tw_k: \n",
    "    consumer_key = tw_k.readline().strip()\n",
    "    consumer_secret = tw_k.readline().strip()\n",
    "    access_key = tw_k.readline().strip()\n",
    "    access_secret = tw_k.readline().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le pasamos nuestras credenciales de twitter a tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name, start_date):\n",
    "    '''\n",
    "    Esta funcion recibe el nombre de la persona de quien queremos extraer los \n",
    "    tweets y devuelve una lista con todos los tweets y sus datos\n",
    "    Input: \n",
    "      screen_name (str): el nombre de la persona en twitter\n",
    "    Output:\n",
    "      all_tweets (lista): lista con todos los tweets extraidos\n",
    "    '''\n",
    "    # Solicitamos los 200 tweets mas recientes (200 es el maximo permitido en count)\n",
    "    new_tweets = api.user_timeline(screen_name=screen_name, \n",
    "                                   tweet_mode=\"extended\", count=200)\n",
    "    # Creo una lista para almacenar TODOS los tweets y agrego los recién extraidos\n",
    "    all_tweets = []\n",
    "    all_tweets.extend(new_tweets)\n",
    "    # guardo el id del ultimo tweet extraído \n",
    "    oldest = all_tweets[-1].id \n",
    "    \n",
    "    # extraigo tweets de a 200 hasta que no haya más\n",
    "    while len(new_tweets) > 0 and all_tweets[-1].created_at > start_date:\n",
    "        # Solicito 200 tweets mas y los agrego a la lista de 'all_tweets'\n",
    "        new_tweets = api.user_timeline(screen_name=screen_name, count=200,\n",
    "                                       tweet_mode=\"extended\", max_id=oldest-1)\n",
    "        all_tweets.extend(new_tweets)\n",
    "        # actualizo el id del ultimo tweet extraído\n",
    "        oldest = all_tweets[-1].id \n",
    "        print(\"Hasta ahora se han extraido %s tweets\" % len(all_tweets))\n",
    "\n",
    "    return all_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_before_elections = datetime(2020, 10, 16, 0, 0, 0)\n",
    "all_tweets_biden = get_all_tweets(\"JoeBiden\", date_before_elections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veamos la lista con los primeros 5 tweets \n",
    "all_tweets_biden[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweets_text(all_tweets, csv_file=None):\n",
    "    '''\n",
    "    Esta función guarda los tweets en un data frame y si se especifica un \n",
    "    archivo csv tambien se guardaran ahí \n",
    "    Input:\n",
    "        all_tweets (lista): lista con tweets y sus datos\n",
    "        csv_file ('str'): nombre del archivo csv\n",
    "    Output:\n",
    "        df_all_tweets (df): tweets ordenados en una tabla con datos seleccinados\n",
    "    '''\n",
    "    all_tweets_selection = []\n",
    "    for tweet in all_tweets:\n",
    "        one_tweet = [tweet.id_str, tweet.created_at, tweet.full_text, \n",
    "                     tweet.retweeted, tweet.favorite_count, \n",
    "                     tweet.in_reply_to_screen_name]\n",
    "        all_tweets_selection.append(one_tweet)\n",
    "    \n",
    "    df_all_tweets = pd.DataFrame(all_tweets_selection)\n",
    "    df_all_tweets.columns = ['id_str', 'created_at', 'text', 'retweeted',\n",
    "                            'favorite_count', 'in_reply_to_screen_name']\n",
    "    if csv_file:\n",
    "        df_all_tweets.to_csv(csv_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    return df_all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_tweets = save_tweets_text(all_tweets_biden, \"tweets.csv\")\n",
    "df_all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emoticons contentos\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    " \n",
    "# Emoticons Tristes\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    "\n",
    "#combine sad and happy emoticons\n",
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # simbolos & pictogramas\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transporte & simbolos mapas\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # banderas (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mrhod clean_tweets()\n",
    "def clean_tweets(tweet):\n",
    "    '''\n",
    "    Esta función limpia el texto del tweet. Elimina emoticones, palabras vacías,\n",
    "    links, indicaciones de retweets, etc. Para dejar en el texto solo las\n",
    "    palabras con mayor contenido.\n",
    "    Input:\n",
    "        tweet (str): Texto del tweet original\n",
    "    Output:\n",
    "        tweet (str): Texto del tweet limpiado\n",
    "    '''\n",
    "    #Elimino caracteres de re-tweets   \n",
    "    tweet = re.sub(r'^RT .*:', '', tweet)\n",
    "    tweet = re.sub(r'@\\S+', '', tweet)\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "    #Reemplazo caracteres non-ASCII con espacio\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "    #Saco los links\n",
    "    tweet = re.sub(r'https.*', '', tweet)\n",
    "    #Saco los emoji\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "    \n",
    "    #Separo los tweets in tokens\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    #Obtengo set de palabras vacias para luego eliminarlas\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    #loop por las condiciones\n",
    "    filtered_tweet = []\n",
    "    for w in word_tokens:\n",
    "        #check tokens against stop words , emoticons and punctuations\n",
    "        if w not in stop_words and w not in emoticons and \\\n",
    "           w not in string.punctuation:\n",
    "            filtered_tweet.append(w)\n",
    "\n",
    "    \n",
    "    return ' '.join(filtered_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este es un tweet sucio:\n",
    "df_all_tweets.iloc[3]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Este es un tweet limpio:\n",
    "clean_tweets(df_all_tweets.iloc[3]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.strptime(\"2020-10-20\", '%Y-%m-%d')\n",
    "end_time = datetime.strptime(\"2020-11-18\", '%Y-%m-%d')\n",
    "\n",
    "def filter_year_and_month(date, start_time, end_time):\n",
    "    '''\n",
    "    Recibe una fecha y devuelve True, si la fecha de la fila esta \n",
    "    dentro de los dias especificados como inicio y fin, caso \n",
    "    contrario False.\n",
    "    '''\n",
    "    dd = datetime.strptime(str(date), '%Y-%m-%d %H:%M:%S')\n",
    "    return dd > start_time and dd < end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentiment(texto):\n",
    "    '''\n",
    "    Esta funcion limpia el texto y analiza el sentimiento.\n",
    "    Input:\n",
    "        texto (str): texto a limpiar y analizar\n",
    "    Output:\n",
    "         polarity (float): en el rango [-1.0, 1.0] \n",
    "         subjectivity (float): en el rango [0.0, 1.0] \n",
    "    '''\n",
    "    # Limpiamos el texto del tweet\n",
    "    filtered_tweet = clean_tweets(texto)\n",
    "    # Calculamos el sentimiento con el metodo TextBlob\n",
    "    blob = TextBlob(filtered_tweet)\n",
    "    Sentiment = blob.sentiment\n",
    "\n",
    "    polarity = Sentiment.polarity\n",
    "    subjectivity = Sentiment.subjectivity            \n",
    "\n",
    "    return polarity, subjectivity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sentiment(df, start_time, end_time):\n",
    "    '''\n",
    "    Esta funcion filtra los tweets entre las fechas de inicio y fin\n",
    "    indicadas y agrega dos columnas, una de polarity y otra de subjectivity.\n",
    "    Input:\n",
    "        df (dataframe): tabla con los tweets en una columa llamada text\n",
    "        start_time (datetime): fecha del tweet más antiguo a conservar\n",
    "        end_time (datetime): fecha del tweet más reciente a conservar\n",
    "    Output:\n",
    "        df (dataframe): df actualizado con el filtro y nuevas columnas\n",
    "    '''\n",
    "    df = df[df.apply(lambda row: filter_year_and_month(row['created_at'], \n",
    "                                                start_time, end_time), axis=1)]\n",
    "\n",
    "    df[[\"polarity\", \"subjectivity\"]] = pd.DataFrame(df.apply(lambda row: \\\n",
    "                                            generate_sentiment(row['text']), \\\n",
    "                                            axis=1).tolist(), index=df.index)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sentimiento = add_sentiment(df_all_tweets, start_time, end_time)\n",
    "tweets_sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 1: \n",
    "Impriman algunos de los tweets más negativos (filtrando por la columna de `polarity`) y su fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 2: \n",
    "Impriman algunos de los tweets más positivos (filtrando por la columna de `polarity`) y su fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 3: \n",
    "Agreguenle al df llamado `tweets_sentimiento` una nueva columna llamada `positivo` que tenga:\n",
    "- 1 cuando el tweet tiene polarity > 0, \n",
    "- 0 cuando el tweet tiene polarity = 0, \n",
    "- 1 cuando el tweet tiene polarity < 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio 4: \n",
    "Agrupen los tweets por día y promedien el la polaridad. Luego hagan un gráfico con el sentimiento por día."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repaso del análisis de sentimiento: \n",
    "Por último, los invito a que exploren el análisis de sentimiento de forma teórica y práctica:\n",
    "- Revisen la documentación de `TextBlob` y del método `sentiment` https://textblob.readthedocs.io/en/dev/ \n",
    "- Prueben en la practica el resultado que arroja para determinadas frases (les dejo unos ejemplos, pero pueden probar los que quieran)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob('good')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob('bad')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob('Hate the quarentine')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob('Love my life')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
